{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035e7689-d67e-4a4e-92d2-49bbbcc6d2d6",
   "metadata": {},
   "source": [
    "# Initial Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b3b054-4d87-4bbd-a14c-bddae70ad499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6983327-214a-4091-8416-32a21752e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_csv('Data/team_names.csv')\n",
    "\n",
    "teams['abbr1'] = teams['abbr1'].str.lower()\n",
    "teams['abbr2'] = teams['abbr2'].str.lower()\n",
    "\n",
    "teams['nickname'] = teams.apply(lambda x: x['full_name'][x['full_name'].rfind(' ') + 1:], axis = 1)\n",
    "\n",
    "teams['abbr1'][teams['abbr1'] == 'arz'] = 'crd'\n",
    "teams['abbr1'][teams['abbr1'] == 'blt'] = 'rav'\n",
    "teams['abbr1'][teams['abbr1'] == 'clv'] = 'cle'\n",
    "teams['abbr1'][teams['abbr1'] == 'hst'] = 'htx'\n",
    "teams['abbr1'][teams['abbr1'] == 'wsh'] = 'was'\n",
    "\n",
    "positions = ['QB', 'RB', 'FB', 'WR1', 'WR2', 'TE', 'LT', 'LG', 'C ', 'RG', 'RT', \n",
    "             'LDE', 'LDT', 'RDT', 'RDE', 'LLB', 'MLB', 'RLB', 'LCB', 'RCB', 'SS', 'FS',\n",
    "             'PR', 'KR']\n",
    "\n",
    "yr_list = [2018, 2019, 2020, 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86a5d37-9b03-4e9a-9f63-5b5f0607feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_dates = pd.read_csv('Data/spreadspoke_scores.csv')\n",
    "\n",
    "game_dates['schedule_date'] = pd.to_datetime(game_dates['schedule_date'], format = '%m/%d/%Y')\n",
    "\n",
    "game_dates = game_dates[game_dates['schedule_date'] >= '2018-06-01']\n",
    "\n",
    "game_dates = game_dates[['schedule_date', 'team_home']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dce348a-340b-413c-b42a-9c871930792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_dates = teams.merge(game_dates, left_on = 'full_name', right_on = 'team_home')\n",
    "\n",
    "team_dates = team_dates[['abbr1', 'schedule_date', 'nickname']]\n",
    "\n",
    "team_dates_dict = dict()\n",
    "\n",
    "for t in team_dates['abbr1'].unique():\n",
    "    \n",
    "    team_dates_dict[t] = dict()\n",
    "    \n",
    "    team_dates_dict[t]['nickname'] = team_dates[team_dates['abbr1'] == t]['nickname'].unique()\n",
    "    \n",
    "    team_dates_dict[t]['dates'] = team_dates[team_dates['abbr1'] == t]['schedule_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9544d5-f325-4b7f-a6cf-64af5dd9234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def starting(abbreviation, team_dates):\n",
    "        \n",
    "    lineup_dict = dict()\n",
    "    \n",
    "    # Initialize the connection\n",
    "    \n",
    "    for dts in team_dates[abbreviation]['dates']:\n",
    "    \n",
    "        date = str(dts.astype('datetime64[D]'))\n",
    "        \n",
    "        print (dts)\n",
    "\n",
    "        date = date[:4] + date[5:7] + date[8:10]\n",
    "\n",
    "        url = 'https://www.pro-football-reference.com/boxscores/' + date + '0' + abbreviation + '.htm'\n",
    "\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument('--headless')\n",
    "        chrome_options.add_argument('--no-sandbox')\n",
    "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "        driver = webdriver.Chrome(executable_path='/usr/local/bin/chromedriver', options=chrome_options)\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Find location of starter data\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        table_loc = 0\n",
    "\n",
    "        for s in soup.find_all(class_ = 'content_grid'):\n",
    "\n",
    "            if s.get_text().find(team_dates[abbreviation]['nickname'][0] +  ' Starters') != -1:\n",
    "\n",
    "                table_loc = count\n",
    "\n",
    "            else:\n",
    "\n",
    "                count += 1\n",
    "\n",
    "        # Extract player list\n",
    "\n",
    "        start_ind = 0\n",
    "\n",
    "        parse_obj = soup.find_all(class_ = 'content_grid')[table_loc].prettify()\n",
    "\n",
    "        player_list = []\n",
    "\n",
    "        start_player = 1\n",
    "\n",
    "        while start_player != -1:\n",
    "\n",
    "            start_player = parse_obj.find('.htm\"')\n",
    "            end_player = parse_obj.find('</a')\n",
    "\n",
    "            player_name = parse_obj[start_player + 6: end_player]\n",
    "\n",
    "            player_list.append(player_name)\n",
    "\n",
    "            start_ind = end_player + 3\n",
    "\n",
    "            parse_obj = parse_obj[start_ind:]\n",
    "        \n",
    "        lineup_dict[dts] = dict()\n",
    "        \n",
    "        lineup_dict[dts]['home'] = player_list[:22]\n",
    "        \n",
    "        lineup_dict[dts]['away'] = player_list[22:-1]\n",
    "    \n",
    "    return lineup_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414531b4-ade1-470f-881b-1b1b653e00fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-09T00:00:00.000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24739/167241464.py:22: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path='/usr/local/bin/chromedriver', options=chrome_options)\n"
     ]
    }
   ],
   "source": [
    "lineups = dict()\n",
    "\n",
    "for abr in team_dates_dict:\n",
    "    \n",
    "    lineups[abr] = starting(abr, team_dates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf02002-6307-4e93-8f84-36847b607468",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.pro-football-reference.com/boxscores/201809090min.htm'\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='/usr/local/bin/chromedriver', options=chrome_options)\n",
    "driver.get(url)\n",
    "time.sleep(20)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108aaa00-9533-4f30-8ca9-4927a3a55ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "table_loc = 0\n",
    "\n",
    "for s in soup.find_all(class_ = 'content_grid'):\n",
    "    \n",
    "    if s.get_text().find('Vikings Starters') != -1:\n",
    "    \n",
    "        table_loc = count\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9153a55-b351-4330-ad10-bb8d1a65caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ind = 0\n",
    "\n",
    "parse_obj = soup.find_all(class_ = 'content_grid')[table_loc].prettify()\n",
    "\n",
    "player_list = []\n",
    "\n",
    "start_player = 1\n",
    "\n",
    "while start_player != -1:\n",
    "    \n",
    "    start_player = parse_obj.find('.htm\"')\n",
    "    end_player = parse_obj.find('</a')\n",
    "            \n",
    "    player_name = parse_obj[start_player + 6: end_player]\n",
    "    \n",
    "    player_list.append(player_name)\n",
    "    \n",
    "    start_ind = end_player + 3\n",
    "        \n",
    "    parse_obj = parse_obj[start_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aaefba-180c-4d49-97c2-07fe85bb9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d6494-1560-4c2c-af6f-8b07ff876979",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b15d05-a481-4a01-a9c9-ce9c361709dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def starting(team, years, positions):\n",
    "    \n",
    "#     Initialize the connection\n",
    "    \n",
    "    url = 'https://www.pro-football-reference.com/teams/' + team + '/lineups.htm'\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path='/usr/local/bin/chromedriver', options=chrome_options)\n",
    "    driver.get(url)\n",
    "    time.sleep(20)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    page = soup.find(id = 'div_starting_lineups').get_text()\n",
    "    \n",
    "#     Find the parts of the text that are associated with each year\n",
    "    \n",
    "    yr_dict = dict()\n",
    "    \n",
    "    for yr in years:\n",
    "    \n",
    "        yr_dict[yr] = page.find(str(yr))\n",
    "        \n",
    "    table_dict = dict()\n",
    "\n",
    "    for yr in years[::-1]:\n",
    "\n",
    "        start_yr = years[yr]\n",
    "\n",
    "        try:\n",
    "            end_yr = years[yr-1]\n",
    "\n",
    "        except:\n",
    "            end_yr = 9999999999999\n",
    "\n",
    "        table_dict[yr] = page[start_yr:end_yr]\n",
    "        \n",
    "#         Parse each year's table\n",
    "        \n",
    "    player_year = dict()\n",
    "        \n",
    "    for t in table_dict:\n",
    "        \n",
    "        player_info = table_dict[t].replace('*', '').replace('+', '')\n",
    "                \n",
    "        str_pos = []\n",
    "\n",
    "        for p in positions:\n",
    "\n",
    "            if p == 'WR1' and p != 'WR2':\n",
    "\n",
    "                wr1 = player_info.find('WR')\n",
    "                wr2 = player_info.rfind('WR')\n",
    "\n",
    "                str_pos.append(wr1)\n",
    "                str_pos.append(wr2)\n",
    "\n",
    "            elif p != 'WR1' and p != 'WR2':\n",
    "\n",
    "                str_pos.append(player_info.find(p))\n",
    "\n",
    "        player_dict = dict()\n",
    "\n",
    "        for p in range(len(off_str_pos)):\n",
    "\n",
    "            if p < (len(off_str_pos) - 1):\n",
    "\n",
    "                player_dict[positions[p]] = (player_info[str_pos[p]: str_pos[p + 1]])\n",
    "\n",
    "                if positions[p] == 'WR1' or positions[p] == 'WR2':\n",
    "\n",
    "                    player_dict[positions[p]] = player_dict[positions[p]].replace('WR', '').strip()\n",
    "\n",
    "                else:\n",
    "\n",
    "                    player_dict[positions[p]] = player_dict[positions[p]].replace(positions[p], '').strip()\n",
    "\n",
    "            else:\n",
    "\n",
    "                player_dict[positions[p]] = player_info[str_pos[p]:].replace(positions[p], '').strip()\n",
    "                \n",
    "        player_year[t] = player_dict\n",
    "        \n",
    "    return player_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc77fa0-070f-443c-a1ff-add27c27366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f66629-fa4f-4c9e-b7a8-94ea9f6bc3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "certificate_folder = '/usr/local/share/ca-certificates/'\n",
    "\n",
    "!wget -P $certificate_folder https://artifactory.chrobinson.com/artifactory/automated-software-storage/ca-certificates/CHR_root.crt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2aa5e5-9bc1-4738-a2f5-27d28443594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results dictionary\n",
    "\n",
    "intermediate_dwell_dict = dict()\n",
    "\n",
    "# Certificate location\n",
    "\n",
    "certificate_location = certificate_folder + '/CHR_root.crt'\n",
    "\n",
    "# Create list to loop through needs to be more than 1 port\n",
    "\n",
    "unloc_list = ['USLAX', 'USLGB', 'USNYC']\n",
    "\n",
    "for unloc in :\n",
    "\n",
    "    new_api = requests.get(url = 'https://port-dwell-vis.api.chrazure.cloud/port_dwell/' + unloc, \n",
    "                           verify = certificate_location)\n",
    "            \n",
    "    intermediate_dwell_dict[unloc] =  new_api.json()\n",
    "    \n",
    "new_data = pd.DataFrame.from_dict(intermediate_dwell_dict).transpose()  # creates dataframe with specified data\n",
    "\n",
    "new_data.to_csv(r\"new_FILEPATH\") #saves data to a csv to import to PBI Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79209baa-c0b6-482a-9e22-c5733a1b4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P /usr/local/share/ca-certificates/ https://artifactory.chrobinson.com/artifactory/automated-software-storage/ca-certificates/CHR_root.crt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b402e6-465f-45f9-98ec-b4ef5b3ca933",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P /usr/local/share/ca-certificates/  https://artifactory.chrobinson.com/artifactory/automated-software-storage/ca-certificates/CHR_intermediate.crt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e14ce6-d28d-44e0-a88f-364286c42bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get -y install ca-certificates && apt-get clean && update-ca-certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68463720-6d2a-4ab1-bb95-45c09cf085d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = requests.get('https://port-dwell-vis.api.chrazure.cloud/port_dwell/USLAX', \n",
    "#                      verify=['/usr/local/share/ca-certificates/CHR_intermediate.crt',\n",
    "#                           '/usr/local/share/ca-certificates/CHR_root.crt'])\n",
    "\n",
    "resp = requests.get('https://port-dwell-vis.api.chrazure.cloud/port_dwell/USLAX', \n",
    "                     verify='/usr/local/share/ca-certificates/CHR_root.crt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555457ed-10ff-4f63-a03d-669b32c51a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
